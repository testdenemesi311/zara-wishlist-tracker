import os
import time
import json
import smtplib
import re
from email.mime.text import MIMEText
from bs4 import BeautifulSoup
from seleniumbase import SB

# ================== AYARLAR ==================

WISHLIST_URL = os.getenv("WISHLIST_URL")
EMAIL_USER = os.getenv("EMAIL_USER")
EMAIL_PASS = os.getenv("EMAIL_PASS")
TO_EMAIL = os.getenv("TO_EMAIL")

# Hangi bedenleri takip ediyoruz?
TARGET_SIZES = ["XS", "S", "M", "L"]

# ================== YARDIMCI FONKSÄ°YONLAR ==================

def send_email(subject, body):
    if not EMAIL_USER or not EMAIL_PASS:
        print("âš ï¸ Mail bilgileri eksik, gÃ¶nderim yapÄ±lmadÄ±.")
        return
    try:
        msg = MIMEText(body, "plain", "utf-8")
        msg["Subject"] = subject
        msg["From"] = EMAIL_USER
        msg["To"] = TO_EMAIL

        with smtplib.SMTP("smtp.gmail.com", 587) as s:
            s.starttls()
            s.login(EMAIL_USER, EMAIL_PASS)
            s.send_message(msg)
        print("âœ… Mail baÅŸarÄ±yla gÃ¶nderildi.")
    except Exception as e:
        print(f"âŒ Mail hatasÄ±: {e}")

def check_stock_via_schema(sb, product_url):
    """
    Sayfadaki 'application/ld+json' scriptini bulur ve parse eder.
    API Ã§aÄŸÄ±rmaz, doÄŸrudan HTML iÃ§indeki veriyi okur.
    """
    sb.open(product_url)
    # SayfanÄ±n render olmasÄ± iÃ§in kÄ±sa sÃ¼re bekle
    time.sleep(4) 
    
    soup = BeautifulSoup(sb.get_page_source(), "html.parser")
    
    # TÃ¼m JSON-LD scriptlerini bul
    scripts = soup.find_all("script", {"type": "application/ld+json"})
    
    product_data = []
    
    for script in scripts:
        try:
            data = json.loads(script.string)
            
            # Bazen data liste gelir (senin Ã¶rneÄŸindeki gibi), bazen obje gelir.
            # Hepsini listeye Ã§evirelim ki dÃ¶ngÃ¼ye sokabilelim.
            if isinstance(data, dict):
                data = [data]
                
            # Ä°Ã§inde "Product" ve "offers" geÃ§en veriyi arÄ±yoruz
            for item in data:
                if item.get("@type") == "Product" and "offers" in item:
                    product_data.append(item)
                    
        except Exception:
            continue

    if not product_data:
        print("   âš ï¸ Schema verisi bulunamadÄ±!")
        return [], ""

    # ÃœrÃ¼n adÄ±nÄ± ilk elemandan alalÄ±m
    product_name = product_data[0].get("name", "ÃœrÃ¼n")
    available_sizes = []

    print(f"   ğŸ·ï¸  ÃœrÃ¼n: {product_name}")

    for item in product_data:
        size = item.get("size")
        offer = item.get("offers", {})
        availability = offer.get("availability", "")
        
        # URL formatÄ±nda gelir: "https://schema.org/InStock"
        status = "STOKTA YOK"
        is_in_stock = False

        if "InStock" in availability:
            status = "VAR"
            is_in_stock = True
        elif "LimitedAvailability" in availability:
            status = "AZ KALDI"
            is_in_stock = True
        
        # Log ekranÄ±na yazdÄ±ralÄ±m
        print(f"   ğŸ‘‰ Beden: {size:<4} | Durum: {status}")

        if size in TARGET_SIZES and is_in_stock:
            available_sizes.append(f"{size} ({status})")

    return available_sizes, product_name

# ================== MAIN ==================

def main():
    if not WISHLIST_URL:
        print("âŒ WISHLIST_URL tanÄ±mlÄ± deÄŸil!")
        return

    # Browser'Ä± baÅŸlat
    with SB(uc=True, headless=True, page_load_strategy="normal") as sb:
        print("ğŸš€ TarayÄ±cÄ± baÅŸlatÄ±lÄ±yor (Schema Mode)...")
        
        # 1. Wishlist'ten Linkleri Topla
        try:
            print(f"ğŸ“‚ Wishlist taranÄ±yor...")
            sb.open(WISHLIST_URL)
            time.sleep(5)
            sb.scroll_to_bottom()
            time.sleep(2)
            
            soup = BeautifulSoup(sb.get_page_source(), "html.parser")
            product_links = set()
            
            # Sadece Ã¼rÃ¼n linklerini al, ID yerine direkt link saklÄ±yoruz
            for a in soup.find_all('a', href=True):
                href = a['href']
                # Zara Ã¼rÃ¼n linki kontrolÃ¼ (-p...html)
                if "-p" in href and ".html" in href:
                    # Linkin temiz halini alalÄ±m
                    full_link = href if href.startswith("http") else f"https://www.zara.com{href}"
                    product_links.add(full_link)
            
            print(f"ğŸ“¦ Bulunan Link SayÄ±sÄ±: {len(product_links)}")
            
        except Exception as e:
            print(f"âŒ Wishlist okuma hatasÄ±: {e}")
            return

        found_products = []

        # 2. Her linke git ve Schema kontrolÃ¼ yap
        for link in product_links:
            print(f"\nğŸ” Linke gidiliyor: {link}")
            
            sizes, name = check_stock_via_schema(sb, link)
            
            if sizes:
                print(f"   âœ… BULUNDU: {sizes}")
                found_products.append(f"ğŸ‘— {name}\nBedenler: {', '.join(sizes)}\n{link}")
            
            # HÄ±zlÄ± istek atÄ±p banlanmamak iÃ§in bekle
            time.sleep(2)

        # 3. SonuÃ§
        if found_products:
            subject = "ğŸš¨ ZARA STOK YAKALANDI!"
            body = "\n\n".join(found_products)
            send_email(subject, body)
        else:
            print("\nğŸ Tarama bitti, stok yok.")

if __name__ == "__main__":
    main()
